<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
  <meta name="google-site-verification" content="AVrJgG2apjS0KBid9YDIJhKjxLiEPB_h3P-rWfkzI14" />
    <meta name="viewport" content="width=device-width, initial-scale=1, minimal-ui">
    <title>Bhumit Sheth</title>
    <link rel="stylesheet" href="github-markdown.css">
    <style>
      body {
        box-sizing: border-box;
        min-width: 200px;
        max-width: 980px;
        margin: 0 auto;
        padding: 45px;
      
    @media screen and (max-width: 360px) {
        img {
        display: block;
        width: 100%;
        }
      }
    }
    </style>
  </head>
  <body>
    <article class="markdown-body">
      <p align="center">
        
      </p>

    <div id="personal-info">
        <img src="./images/images_1.png" width="200" alt="" BORDER="0" ALIGN="Left"/>
        <p><font size="5"><b>Bhumit Sheth</b></font></p>
        <p><font size="4">Business Intelligence | Data Science </font></p>
        <p><font size="3">W. P. Carey School of Business</font></p>
        <p><font size="3">Arizona State University</font></p>
        <p><font size="3"><a href="mailto:bsheth2@asu.edu">Email</a> | <a href="./documents/resume.pdf">Resume</a></font></p>

    </div>


<div style="clear:both">
  
    <h2>About Me</h2>
    <p> I am currently a Business Analytics Student at <a href="https://wpcarey.asu.edu/">W. P. Carey School of Business</a>, <a href="https://www.asu.edu/">Arizona State University</a>.</p>
  
   
    <p> As an empiricist, I am passionate in applying and developing data science tools to solve novel challenges in business. Working at Cairn Oil and Gas, India, I utilize Python, SQL, and Tableau to analyze and visualize large datasets, optimize drilling operations, and deliver operational strategies. I have achieved a $3MM cost reduction, a 10% efficiency improvement, and a 2-month project acceleration, among other results. I focused myself to imporve the supply chain of the drill pipe among other drilling inventory. I even managed drilling contracts (including LSTK) and service contracts for third parties.</p>
    
    <p> I obtained my Bachelors degree from the <a href="https://petroleum.iitism.ac.in/">Petroleum Engineering Department </a> of <a href="https://www.iitism.ac.in/">Indian Institute of Technology (Indian School of Mines), Dhanbad </a>. Prior to joining ASU as a Business Analytics Grad student, I was working at <a href="https://www.cairnindia.com/Pages/Home.aspx">Cairn Oil and Gas, Vedanta Limited, India</a>. 
    
    <h2>Ongoing Research Work</h2>
    <p>Working at <a href="https://supplychainresilience.wpcarey.asu.edu/">Supply Chain Resilience Initiative</a> with instructors: Professor Eugene Schneller & Professor Mikaella Polyviou</p> 
    <ul>
    <li>Gained invaluable insights on business resilience strategies from leaders of eight diverse organisations, learning how evidence-based management and implementation  science are essential for sustained change in healthcare services.<br></li>
    <li>Collaborating in the compilation of a comprehensive white paper that will encapsulate strategic learnings and best practices for enhancing organisational resilience, aiming to bridge the gap between research and practice in healthcare management.</li>
      </ul>

    <h2>Ongoing Project</h2>
    <ol>
    <li>I am currently working with a team from <a href="https://www.apllogistics.com/">APL Logistics, USA</a> as part of my capstone project coursework. 
    <p> I led a comprehensive end-to-end project along with 4 graduates, culminating in a Streamlit app to forecast ETA/ETD for ocean shipments, enhancing supply chain visibility. Key achievements include:</p>
    <ul>
    <li>Analyzed data from 3 customers, covering 54k shipments and 211 routes.</li>
    <li>AEnhanced the predictive model with static (e.g., holidays) and dynamic factors (e.g., port congestion, weather disruptions).</li>
    <li>AConducted EDA using Tableau, evaluating 23 carriers across various routes.</li>
    <li>ADeveloped a machine learning model (employing algorithms such as Random Forest, Gradient Boosting, MLR, and Neural Networks) with an R2 score of 0.78, demonstrating high predictive accuracy.</li>
    <li>ASuccessfully deployed a Streamlit application showcasing the model's capability to predict shipment times accurately, improving operational efficiency in logistics.</li>
    </ul>  
    </li>
    <li>For my Green Belt Certification, I am working on a project with <a href="https://nib.org/"> National Industries for the Blind.</a>  My knowledge of Lean Principles and the DMAIC Methodology stems from my coursework in Business Process Analytics. My team's attention will be directed towards the following areas: </li>
    <ul>
    <li>Analyze NIB's NPA growth trends and AbilityOne sales to identify the Matthew Effect, using Excel for data analysis from FY2013 to FY2023.</li>
    <li>Investigate growth disparities among NPAs, providing insights for policy adjustments to promote blind employment within NIB.</li>
    </ul>
    </ol>
  
    <h2>Completed Projects</h2>
    <ol>
    <li><b>Airbnb Review Analytics</b>
    <a href="https://public.tableau.com/app/profile/bhumit.sheth/viz/DashboardAmesterdamAirbnb/Dashboard1">[Tableau]</a>
    <a href="https://github.com/shethbhumit/airbnb_reviews_analytics">[Code]</a><br>
    <em>Unlocking Airbnb Success Stories.</em> <br>As a passionate enthusiast and key business stakeholder, our primary goal was to understand how Airbnb hosts were performing in Amsterdam. We sought answers to the question: "How much are the top Airbnb owners making in Amsterdam?" This insight provides a glimpse into the lucrative world of short-term rentals.<br>

    <em>Catering to a Niche Market. </em><br> With a long-standing desire to establish an Airbnb Cleaning Business, we embarked on a quest to identify potential customers. By dissecting the data, we aimed to answer the question: "Who comprises the potential customer list for our Airbnb Cleaning Business?" This critical knowledge forms the foundation for our future entrepreneurial endeavors.
    </li>
    <br>
    <li><b>Fraud Detection Using Predictive Analysis</b>
      <a href="https://github.com/shethbhumit/Fraud-Detection-Using-Predictive-Analysis">[Code]</a><br> 
      Abstract: A large number of problems in data mining are related to fraud detection. Fraud is a common problem in auto insurance claims, health insurance claims, credit card transactions, financial transaction and so on. The data in this particular case comes from an actual auto insurance company. Each record represents an insurance claim. The last column in the table tells you whether the claim was fraudulent or not.<br>

      <br> Learnings: 
      <ul>
      <li>Dealing with categorical data: OneHotEncoder, getdummies, label-encoder</li>
      <li>HyperParameter Tuning using GridSearch and RandomSearch Methods</li>
      <li>Building a Random Forest Classifier</li>
      <li>Model Evaluation: More focus on False Negatives</li>
      </ul>

    </li>
    <br> 
    <li><b>Predicting Homesite Insurance Quotes</b>
      <a href="https://github.com/shethbhumit/Homesite_Quote_Conversion">[Code]</a><br> 
      This dataset represents the activity of a large number of customers who are interested in buying policies from Homesite. Each QuoteNumber corresponds to a potential customer and the QuoteConversion_Flag indicates whether the customer purchased a policy.<br>
      The provided features are anonymized and provide a rich representation of the prospective customer and policy. They include specific coverage information, sales information, personal information, property information, and geographic information. Your task is to predict QuoteConversion_Flag for each QuoteNumber in the test set.<br>

      <br> Work & Results: 
      <ul>
      <li>Predicted the probability that a customer would buy a quoted insurance plan, using different classification methods in Python.</li>
      <li>Built an ensemble prediction (one-layer-stacking) model, using Decision Tree, Random Forest, Support Vector Machines, Multi- Layer Perceptron and K-Nearest Neighbors classifiers accomplishing 90% + accuracy</li>
      
      </ul>

    </li>
    <br> 
    <li><b>Santander Customer Satisfaction</b>
      <a href="https://github.com/shethbhumit/Santander-Customer-Satisfaction">[Code]</a><br> 
      Abstract: Santander Bank is asking Kagglers to help them identify dissatisfied customers early in their relationship. Doing so would allow Santander to take proactive steps to improve a customer's happiness before it's too late.
      In this project, we work with hundreds of anonymized features to predict if a customer is satisfied or dissatisfied with their banking experience.<br>
      We implement a decision tree classifier model from the Scikit-learn library to predict the class. We will initially evaluate the default decision tree model and step by step explore differnent parameters of the decision tree classifier to improve the model.<br> 

      <br> Learnings: 
      <ul>
      <li>Building a Classification model using Decision Tree Classfier.</li>
      <li>Manually tuning ML Models for better accuracy and ROC score.</li>
      <li>Model Evaulation using Accuracy, Precision, Recall and ROC curves</l
      </ul>

    </li>
  

    </ol>

    <h2>Leadership & Communication </h2>
    <ul>
    <li> Effective Team Leader: Led a team, to conduct drilling operations in offshore well, leveraging analytical approach.</li>

    <li> Strategic Communicator: Vice President at FIPI IIT ISM Dhanbad, enhancing chapter engagement and collaboration.</li>

    <li>Public Speaking Excellence: Secured First Prize in Shell India's Darcy Business Challenge at IIT ISM Dhanbad, 2019.</li>

    <li>Competitive Achiever: Won Environmental Quiz among 500 participants, organized by Cairn Oil and Gas, 2019.</li>
    </ul>
    
    
    <h2>Miscellaneous</h2>
    <ul>        
    <li> <a href="./notes.html">Notes</a></li>
    <li> <a href="./misc.html">Misc. of Misc.</a></li>
      </ul>
</div>
  
<br>

<div id="footer" ALIGN="Middle">
<p><a href="mailto:bsheth2@asu.edu"><img src="./images/mail.png" width="20"/></a></p>
</div>

    </article>
  </body>
</html>
